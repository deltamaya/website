---
title: ArcVeditor DevLog#1
date: '2024-09-22'
tags: ['graphics','devlog','opengl','ffmpeg','media-processing']
draft: false
summary: Step into OpenGL and FFmpeg
---
# What is OpenGL?

Firstly, OpenGL is **not** a library or framework, etc.
It's a graphics API specification, which means it doesn't contains actually code,
like C++. Every GPU manufacturer has their own OpenGL implementation, and that 
explains why your game looks slightly different on NVIDIA and AMD GPU. So 
it's not "Open", the GPU manufacturer doesn't open source their driver's code.

## Then how could I "download" OpenGL?

As I mentioned, the GPU manufacturer already wrote OpenGL in their driver, so if you
have the proper driver for your GPU, then you got OpenGL.

## OpenGL varients
You may see a lot of stuff seems like has some relationship with `OpenGL`, like 
`OpenGL ES`, `WebGL`, etc. Let's introduce them one by one.

### OpenGL ES

**OpenGL ES(Embedded System)**, as you can see, OpenGL ES is designed for Embedded System,
it is a subset of the full OpenGL API, ans is optimized for effientcy and performance on 
these platform whih resources limitation.

### WebGL

**WebGL** is Javascript API based on the OpenGL ES 2.0. Which provides hardware-acceleration
3D graphics to web browsers.

### Vulkan
OpenGL itself is a so called "high-level" API, so it's more abstract and easy to use,
but this feature also causes overhead, it lowers the performance. So the **Vulkan**
cames, it is a more low level graphics API, Vulkan gives you more control to the hardware
and allows you to write some more fast code, but it's more complex to implement.

## Other Graphics API
OpenGL is a cross-platform graphics API and there are still a lot of 
exclusive graphics APIs like Metal and DirectX.
### Metal
**Metal** is a Apple exclusive graphics API which optimized for Apple silicon, which
provides a low level control on Mac and better performance. Metal has replaced OpenGL
on Mac and iPhone, Apple has deprecated support for OpenGL.
### DirectX
Like Metal, **DirectX**(Direct3D, Direct2D, etc.) is a Windows exclusive.
DirectX is a suitcase contains lots of library like Direct2D and Direct3D. 
### CUDA
**CUDA** is not a Graphics API, it is a general purpose programming library on NVIDIA GPU.
With CUDA, you can utilize the power of GPU to process parallel computation.
## Graphic API Management library
As you can see, OpenGl is just a graphics API, what is can do is tell GPU to
render the data you give him. But ArcVeditor is an App, I need a Window, then
where should I go? Yes, you need graphics api management library.
## GLFW
**GLFW** is a light-weight cross-platform OpenGL utility library.
It provides easy to use APIs to create windows and manage OpenGL contexts.

## GLUT
You can regard **GLUT** as a simpler and older version of GLFW.
## SDL
**SDL(Simple DirectMedia Layer)** is also a cross-platform library we can use to
manage OpenGL, SDL has much more feature than GLFW like manages 
video, audio, input devices, threads, shared object loading, 
networking and timers.
SDL can work with OpenGL, but it supports a lot of graphics APIs like Metal and
Direct3D.

# What is FFmpeg?
**FFmpeg** is a open-source library consisting programs to process videos, audios,
multimedia files and streams.

# OpenGL Usage & Explaination
## Sample Code

```cpp
// use glfw to create a window
GLFWwindow *window =
    glfwCreateWindow(1280, 720, "Hello world", nullptr, nullptr);
if (window == nullptr)
  return 1;
// make sure to create the OpenGL context before anything
glfwMakeContextCurrent(window);
// create OpenGl Texture with given data
GLuint texHandle = createTexture(data, frameWidth, frameHeight);
while (!glfwWindowShouldClose(window)) {
  // clear OpenGL background buffer
  glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
  // if the app is in background
  if (glfwGetWindowAttrib(window, GLFW_ICONIFIED) != 0) {
    ImGui_ImplGlfw_Sleep(10);
    continue;
  }

  // start the Dear ImGui frame
  ImGui_ImplOpenGL3_NewFrame();
  ImGui_ImplGlfw_NewFrame();
  ImGui::NewFrame();

  if (show_demo_window)
    ImGui::ShowDemoWindow(&show_demo_window);
  // set OpenGL background color when buffer was cleared
  glClearColor(clear_color.x * clear_color.w, clear_color.y * clear_color.w,
                clear_color.z * clear_color.w, clear_color.w);
  // render the ImGui stuff
  ImGui::Render();
  // draw the texture
  drawQuad(window, frameWidth, frameHeight, texHandle);
  ImGui_ImplOpenGL3_RenderDrawData(ImGui::GetDrawData());
  // swap background buffer and the display buffer
  glfwSwapBuffers(window);
  // use glfw to process window events
  glfwPollEvents();
}
// remember to clean up
ImGui_ImplOpenGL3_Shutdown();
ImGui_ImplGlfw_Shutdown();
ImGui::DestroyContext();
glfwDestroyWindow(window);
glfwTerminate();
```
## Context
An OpenGL context represents many things.
A context stores all of the state associated with this instance of OpenGL. 
It represents the (potentially visible) default framebuffer that rendering 
commands will draw to when not drawing to a framebuffer object. 
Think of a context as an object that holds all of OpenGL; 
when a context is destroyed, OpenGL is destroyed.

Contexts are localized within a particular process of execution 
(an application, more or less) on an operating system. 
A process can create multiple OpenGL contexts. 
Each context can represent a separate viewable surface, 
like a window in an application.
## Texture
A texture is a 2D image (even 1D and 3D textures exist) used to add detail to an object.
Because we can insert a lot of detail in a single image, 
we can give the illusion the object is extremely detailed without having 
to specify extra vertices.
Texture coordinates range from 0 to 1 in the x and y axis 
(remember that we use 2D texture images). 
Retrieving the texture color using texture coordinates is called sampling. 
Texture coordinates **start at (0,0)** for the lower left corner of a texture 
image to **(1,1)** for the upper right corner of a texture image. 

For more detailed version, check: [LearnOpenGL](https://learnopengl.com/Getting-started/Textures)
# FFmpeg Usage & Explaination

## Sample Code
```cpp
bool loadFrame(const char *filename, int *width, int *height,
               std::vector<std::uint8_t> *data) {
  // Allocate memory for avformat
  AVFormatContext *avFormatContext = avformat_alloc_context();
  if (!avFormatContext) {
    defaultLogger.Debug("Unable to create format context");
    return false;
  }
  if (avformat_open_input(&avFormatContext, filename, nullptr, nullptr)) {
    defaultLogger.Debug("Unable to open video file");
    return false;
  }
  int videoStreamIndex = -1;
  const AVCodec *avCodec;
  AVCodecParameters *avCodecParams;
  // Find the first video stream
  for (int i = 0; i < avFormatContext->nb_streams; i++) {
    auto stream = avFormatContext->streams[i];
    avCodecParams = stream->codecpar;
    avCodec = avcodec_find_decoder(avCodecParams->codec_id);
    if (!avCodec) {
      continue;
    }
    if (avCodecParams->codec_type == AVMEDIA_TYPE_VIDEO) {
      videoStreamIndex = i;
      break;
    }
  }
  if (videoStreamIndex == -1) {
    defaultLogger.Debug("Unable to find valid video stream");
  }
  // Set up the codec context for decoder
  AVCodecContext *avCodecContext = avcodec_alloc_context3(avCodec);
  if (!avCodecContext) {
    defaultLogger.Debug("Unable to allocate codec context");
    return false;
  }
  if (avcodec_parameters_to_context(avCodecContext, avCodecParams) < 0) {
    defaultLogger.Debug("Unable to initialize avCodecContext");
    return false;
  }
  if (avcodec_open2(avCodecContext, avCodec, nullptr) < 0) {
    defaultLogger.Debug("Unable to open codec");
    return false;
  }

  AVFrame *avFrame = av_frame_alloc();
  AVPacket *avPacket = av_packet_alloc();
  while (av_read_frame(avFormatContext, avPacket) >= 0) {
    if (avPacket->stream_index != videoStreamIndex) {
      continue;
    }
    int response = avcodec_send_packet(avCodecContext, avPacket);
    if (response < 0) {
      defaultLogger.Debug("Unable to decode packet: ", av_err2str(response));
      continue;
    }
    response = avcodec_receive_frame(avCodecContext, avFrame);
    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {
      continue;
    } else if (response < 0) {
      defaultLogger.Debug("Unable to decode packet: ", av_err2str(response));
      return false;
    }
    av_packet_unref(avPacket);
    break;
  }
  *width = avFrame->width;
  *height = avFrame->height;
  *data = std::vector<std::uint8_t>(avFrame->width * avFrame->height * 3);
  int lineSize = avFrame->linesize[0];
  for (int x = 0; x < avFrame->width; x++) {
    for (int y = 0; y < avFrame->height; y++) {
      (*data)[y * avFrame->width * 3 + x * 3] = avFrame->data[0][y * lineSize + x];
      (*data)[y * avFrame->width * 3 + x * 3 + 1] = avFrame->data[0][y * lineSize + x];
      (*data)[y * avFrame->width * 3 + x * 3 + 2] = avFrame->data[0][y * lineSize + x];
    }
  }
  avformat_close_input(&avFormatContext);
  avformat_free_context(avFormatContext);
  avcodec_free_context(&avCodecContext);
  av_frame_free(&avFrame);
  return true;
}
```
## AVFormatContext
The `AVFormatContext` object contains all the data you should know to process
a media file, such as duration, tracks, and so on. Get the context of a file,
is similar to `demuxing` a media file.
## AVCodec
The `AVCodec` represents the `encoder/decoder` used by the stream.
### AVCodecContext
`AVCodecContext` contains data that the `encoder/decoder` should know to processing
streams. Such as the packet id, etc.
### AVCodecParams
`AVCodecParams` tells you the messages related to the relevant `AVCodec`. Like codec id and codec type.
## AVPacket
A stream consists multiple `packets`, and codec can use them to process frames, 
note that the relation between packet and frame is many to many, a packet **doesn't**
represent a frame, that's why we should use
```cpp
if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {
  continue;
} 
```
to make sure that we already decoded a frame from those packets.
### Reference Counting
The FFmpeg used reference counting to manage `AVPacket` objects, so make sure you
uses `av_packet_unref` to unreference the packet.
## AVFrame
The `AVFrame` decoded from AVPacket contains all the data you should know to render
a single video frame.


